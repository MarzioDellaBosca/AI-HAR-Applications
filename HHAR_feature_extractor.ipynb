{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c221cdf",
   "metadata": {},
   "source": [
    "#### Progetto di corso per APPLICAZIONI DELL'INTELLIGENZA ARTIFICIALE (AA 2024-2025)\n",
    "#### Stud: Marzio Della Bosca\n",
    "\n",
    "\n",
    "Jupyter Notebook con la funzione di estrarre le feature, tramite catch22 e tsfel, dai dati contenuti nel dataset [Heterogeneity Activity Recognition](https://archive.ics.uci.edu/dataset/344/heterogeneity+activity+recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd45a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsfel\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from aeon.transformations.collection.feature_based import Catch22\n",
    "\n",
    "# Gt o label: Biking, Sitting, Standing, Walking, Stair Up, Stair down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f5518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero Dati Accelerometro: 13062475, Head:\n",
      "   Index   Arrival_Time        Creation_Time         x         y         z  \\\n",
      "0      0  1424696633908  1424696631913248572 -5.958191  0.688065  8.135345   \n",
      "1      1  1424696633909  1424696631918283972 -5.952240  0.670212  8.136536   \n",
      "2      2  1424696633918  1424696631923288855 -5.995087  0.653549  8.204376   \n",
      "3      3  1424696633919  1424696631928385290 -5.942718  0.676163  8.128204   \n",
      "\n",
      "  User   Model    Device     gt  \n",
      "0    a  nexus4  nexus4_1  stand  \n",
      "1    a  nexus4  nexus4_1  stand  \n",
      "2    a  nexus4  nexus4_1  stand  \n",
      "3    a  nexus4  nexus4_1  stand  \n",
      "\n",
      "Numero Dati Giroscopio: 13932632, Head:\n",
      "   Index   Arrival_Time        Creation_Time         x         y         z  \\\n",
      "0      0  1424696633909  1424696631914042029  0.013748 -0.000626 -0.023376   \n",
      "1      1  1424696633909  1424696631919046912  0.014816 -0.001694 -0.022308   \n",
      "2      2  1424696633918  1424696631924051794  0.015884 -0.001694 -0.021240   \n",
      "3      3  1424696633919  1424696631929117712  0.016953 -0.003830 -0.020172   \n",
      "\n",
      "  User   Model    Device     gt  \n",
      "0    a  nexus4  nexus4_1  stand  \n",
      "1    a  nexus4  nexus4_1  stand  \n",
      "2    a  nexus4  nexus4_1  stand  \n",
      "3    a  nexus4  nexus4_1  stand  \n"
     ]
    }
   ],
   "source": [
    "accelerometer_data = pd.read_csv('./HHAR_data/Phones_accelerometer_hhar.csv')\n",
    "gyroscope_data = pd.read_csv('./HHAR_data/Phones_gyroscope_hhar.csv')\n",
    "\n",
    "print(f\"Numero Dati Accelerometro: {len(accelerometer_data)}, Head:\")\n",
    "print(accelerometer_data.head(4))\n",
    "\n",
    "print(f\"\\nNumero Dati Giroscopio: {len(gyroscope_data)}, Head:\")\n",
    "print(gyroscope_data.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f58a4717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_list(data_list, freq, window_seconds=2):                 # finestro a 2 secondi in maniera dinamica date le diverse frequenze di campionamento\n",
    "    if freq <= 0 or not isinstance(data_list, list):\n",
    "        return []\n",
    "    window_size = int(freq * window_seconds)\n",
    "    #print(freq)\n",
    "    #print(window_size)\n",
    "    if window_size == 0:\n",
    "        return []\n",
    "    return [data_list[i:i+window_size] \n",
    "            for i in range(0, len(data_list), window_size) \n",
    "            if len(data_list[i:i+window_size]) == window_size]\n",
    "\n",
    "rows = []\n",
    "\n",
    "def catch22_time_series_features_extractor(time_series):\n",
    "    catch22 = Catch22()\n",
    "    startTime = time.time()\n",
    "\n",
    "    # Numero di feature Catch22 per canale (prendo il primo segnale x_acc)\n",
    "    test_features = catch22.fit_transform([np.array(time_series.iloc[0]['x_acc'])])[0]\n",
    "    n_feat = len(test_features)\n",
    "    n_channels = 6  # x_acc, y_acc, z_acc, x_gyr, y_gyr, z_gyr\n",
    "\n",
    "    # Preallocazione array 3D (serie, canali, feature)\n",
    "    features_3d = np.zeros((len(time_series), n_channels, n_feat))\n",
    "    activities = []\n",
    "\n",
    "    channels = ['x_acc', 'y_acc', 'z_acc', 'x_gyr', 'y_gyr', 'z_gyr']\n",
    "\n",
    "    for i, (_, series) in enumerate(tqdm(time_series.iterrows(), total=len(time_series), desc=\"Estrazione Catch22\")):\n",
    "        for j, ch in enumerate(channels):\n",
    "            signal = np.array(series[ch])\n",
    "            features_3d[i, j, :] = catch22.fit_transform([signal])[0]\n",
    "        activities.append(series['activity'])\n",
    "\n",
    "    activities_array = np.array(activities)\n",
    "\n",
    "    print(f\"Tempo di esecuzione per l'estrazione delle feature catch22: {time.time() - startTime:.2f} secondi\")\n",
    "    return features_3d, activities_array\n",
    "\n",
    "\n",
    "def tsfel_time_series_features_extractor_dual(cfg_stat, cfg_temp, time_series):\n",
    "    timeStart = time.time()\n",
    "\n",
    "    # Determina il numero di feature per configurazione e canale usando la prima serie e primo canale\n",
    "    test_feats_stat = tsfel.time_series_features_extractor(cfg_stat, pd.DataFrame(np.array(time_series.iloc[0]['x_acc'])), verbose=0)\n",
    "    n_feat_stat = test_feats_stat.shape[1]\n",
    "\n",
    "    test_feats_temp = tsfel.time_series_features_extractor(cfg_temp, pd.DataFrame(np.array(time_series.iloc[0]['x_acc'])), verbose=0)\n",
    "    n_feat_temp = test_feats_temp.shape[1]\n",
    "\n",
    "    n_channels = 6  # x_acc, y_acc, z_acc, x_gyr, y_gyr, z_gyr\n",
    "\n",
    "    # Prealloca array per feature (stat + temp)\n",
    "    features_3d = np.zeros((len(time_series), n_channels, n_feat_stat + n_feat_temp))\n",
    "    activities = []\n",
    "\n",
    "    channels = ['x_acc', 'y_acc', 'z_acc', 'x_gyr', 'y_gyr', 'z_gyr']\n",
    "\n",
    "    for i, (_, series) in enumerate(tqdm(time_series.iterrows(), total=len(time_series), desc=\"Estrazione TSFEL\")):\n",
    "        for j, ch in enumerate(channels):\n",
    "            signal = pd.DataFrame(np.array(series[ch]))  # Serie temporale canale\n",
    "            feats_stat = tsfel.time_series_features_extractor(cfg_stat, signal, verbose=0, n_jobs=-1)\n",
    "            feats_temp = tsfel.time_series_features_extractor(cfg_temp, signal, verbose=0, n_jobs=-1)\n",
    "            # Concateno le feature stat + temp\n",
    "            combined_feats = np.concatenate((feats_stat.values.flatten(), feats_temp.values.flatten()))\n",
    "            features_3d[i, j, :] = combined_feats\n",
    "        activities.append(series['activity'])\n",
    "\n",
    "    print(f\"Tempo di esecuzione per l'estrazione delle feature tsfel 3D: {time.time() - timeStart:.2f} secondi\")\n",
    "\n",
    "    activities_array = np.array(activities)\n",
    "    return features_3d, activities_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff1f9234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anche se diverse prove mostrano sia in head che in tail che i creation time dei dati di giroscopio e accelerometro sembrano combaciare si nota un'importante mancanza di \n",
    "# campioni dal giroscopio, inoltre sono stati usati diversi cellulari a diverse frequenze di campionamento. Raggruppando per 'User', 'Device' e 'Gt' riesco ad ottenere\n",
    "# delle prove singole o comunque una sequenza di prove con stessa label e stesso dispositivo e tramite numero di campioni e Creation time di inizio e fine riesco a calcolare\n",
    "# in maniera dinamica le frequenze di campionamento e riuscire a mantenere un finestramento di 2 secondi.\n",
    "\n",
    "# estraggo solo le colonne necessarie per ciascun dataset\n",
    "acc_data = accelerometer_data[['User', 'Device', 'gt', 'Creation_Time', 'x', 'y', 'z']].copy()\n",
    "gyro_data = gyroscope_data[['User', 'Device', 'gt', 'Creation_Time', 'x', 'y', 'z']].copy()\n",
    "\n",
    "# raggruppo per User, Device, gt e aggrego dati in liste\n",
    "acc_grouped = acc_data.groupby(['User', 'Device', 'gt']).agg({\n",
    "    'Creation_Time': list,\n",
    "    'x': list,\n",
    "    'y': list,\n",
    "    'z': list\n",
    "}).reset_index()\n",
    "\n",
    "gyro_grouped = gyro_data.groupby(['User', 'Device', 'gt']).agg({\n",
    "    'Creation_Time': list,\n",
    "    'x': list,\n",
    "    'y': list,\n",
    "    'z': list\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc_grouped.shape)\n",
    "print(gyro_grouped.shape)\n",
    "\n",
    "print(acc_grouped.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3319fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinazioni solo in accelerometro: 108\n",
      "Combinazioni solo in giroscopio: 1\n",
      "Combinazioni comuni: 307\n"
     ]
    }
   ],
   "source": [
    "# Set delle triple chiave (User, Device, gt) per accelerometro e giroscopio, aggrego i dati da acc e gyr\n",
    "acc_keys = set(acc_grouped.apply(lambda row: (row['User'], row['Device'], row['gt']), axis=1))\n",
    "gyro_keys = set(gyro_grouped.apply(lambda row: (row['User'], row['Device'], row['gt']), axis=1))\n",
    "\n",
    "# Differenze\n",
    "only_in_acc = acc_keys - gyro_keys  # combinazioni presenti solo in acc\n",
    "only_in_gyro = gyro_keys - acc_keys # combinazioni presenti solo in gyro\n",
    "common_keys = acc_keys & gyro_keys   # combinazioni presenti in entrambi\n",
    "\n",
    "print(f\"Combinazioni solo in accelerometro: {len(only_in_acc)}\")\n",
    "print(f\"Combinazioni solo in giroscopio: {len(only_in_gyro)}\")\n",
    "print(f\"Combinazioni comuni: {len(common_keys)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836192e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 7)\n",
      "(307, 7)\n"
     ]
    }
   ],
   "source": [
    "# Definisco una funzione che verifica se la tupla (User, Device, gt) di una riga è in common_keys\n",
    "def is_common(row):\n",
    "    return (row['User'], row['Device'], row['gt']) in common_keys\n",
    "\n",
    "# Filtra acc_grouped mantenendo solo le righe con combinazioni in common_keys\n",
    "acc_filtered = acc_grouped[acc_grouped.apply(is_common, axis=1)].reset_index(drop=True)\n",
    "\n",
    "# Filtra gyro_grouped allo stesso modo\n",
    "gyro_filtered = gyro_grouped[gyro_grouped.apply(is_common, axis=1)].reset_index(drop=True)\n",
    "\n",
    "print(acc_filtered.shape)\n",
    "print(gyro_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5198e241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Le prime 307 chiavi sono uguali?: True\n"
     ]
    }
   ],
   "source": [
    "# o colonna 'key' con la tupla (User, Device, gt), solo per controllo\n",
    "acc_filtered['key'] = list(zip(acc_filtered['User'], acc_filtered['Device'], acc_filtered['gt']))\n",
    "gyro_filtered['key'] = list(zip(gyro_filtered['User'], gyro_filtered['Device'], gyro_filtered['gt']))\n",
    "\n",
    "# Controlla se sono uguali (ordine e valori)\n",
    "print(f\"\\nLe prime {(len(acc_filtered)+len(gyro_filtered))//2} chiavi sono uguali?: {(acc_filtered['key'].head(len(acc_filtered)) == gyro_filtered['key'].head(len(gyro_filtered))).all()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b7b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_filtered = acc_filtered.drop(columns=['key'])\n",
    "gyro_filtered = gyro_filtered.drop(columns=['key'])\n",
    "\n",
    "# Calcola (max - min) per ogni lista di timestamps (registrazioni)\n",
    "acc_filtered['Duration_acc'] = acc_filtered['Creation_Time'].apply(\n",
    "    lambda lst: (max(pd.to_datetime(lst)) - min(pd.to_datetime(lst))) \n",
    "                if isinstance(lst, list) and lst else pd.Timedelta(0)\n",
    ")\n",
    "gyro_filtered['Duration_gyr'] = gyro_filtered['Creation_Time'].apply(\n",
    "    lambda lst: (max(pd.to_datetime(lst)) - min(pd.to_datetime(lst))) \n",
    "                if isinstance(lst, list) and lst else pd.Timedelta(0)\n",
    ")\n",
    "\n",
    "acc_filtered = acc_filtered.drop(columns=['Creation_Time'])\n",
    "gyro_filtered = gyro_filtered.drop(columns=['Creation_Time'])\n",
    "\n",
    "gyro_data_only = gyro_filtered[['Duration_gyr', 'x', 'y', 'z']].rename(columns={\n",
    "    'x': 'x_gyr', 'y': 'y_gyr', 'z': 'z_gyr'\n",
    "})\n",
    "acc_data_only = acc_filtered[['User', 'Device', 'gt', 'Duration_acc', 'x', 'y', 'z']].rename(columns={\n",
    "    'x': 'x_acc', 'y': 'y_acc', 'z': 'z_acc'\n",
    "})\n",
    "\n",
    "merged_df = pd.concat(\n",
    "    [acc_data_only.reset_index(drop=True), gyro_data_only.reset_index(drop=True)],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "739e48df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 11)\n",
      "  User    Device          gt              Duration_acc  \\\n",
      "0    a  nexus4_1        bike 0 days 00:04:59.734857830   \n",
      "1    a  nexus4_1         sit 0 days 00:05:07.898901008   \n",
      "2    a  nexus4_1  stairsdown 0 days 00:07:52.720734654   \n",
      "3    a  nexus4_1    stairsup 0 days 00:07:14.813174234   \n",
      "4    a  nexus4_1       stand 1 days 12:27:10.086740992   \n",
      "\n",
      "                                               x_acc  \\\n",
      "0  [-7.291198700000001, -7.216216999999999, -7.21...   \n",
      "1  [-0.44882202, -0.42739868, -0.41430664, -0.382...   \n",
      "2  [-5.9950867, -6.33667, -6.817505000000001, -7....   \n",
      "3  [-4.3323975, -4.450226, -4.516876, -4.552582, ...   \n",
      "4  [-5.958191, -5.95224, -5.9950867, -5.9427185, ...   \n",
      "\n",
      "                                               y_acc  \\\n",
      "0  [2.3412323, 2.2710114, 2.2710114, 2.2281647, 2...   \n",
      "1  [-0.0962677, -0.07722473, -0.084365845, -0.097...   \n",
      "2  [2.5614166000000003, 2.4066925, 2.2150726, 2.0...   \n",
      "3  [-0.19029236, -0.04270935, 0.21913147, 0.45835...   \n",
      "4  [0.6880646, 0.6702118, 0.6535491999999999, 0.6...   \n",
      "\n",
      "                                               z_acc  \\\n",
      "0  [6.313171400000001, 6.346496599999999, 6.34649...   \n",
      "1  [10.301483, 10.320526, 10.402649, 10.383606, 1...   \n",
      "2  [9.113678, 8.893494, 8.67569, 8.48288, 8.42218...   \n",
      "3  [6.8142395, 6.985626, 7.305786, 7.609283400000...   \n",
      "4  [8.135345, 8.136536, 8.204376, 8.128204, 8.135...   \n",
      "\n",
      "               Duration_gyr  \\\n",
      "0 0 days 00:04:59.734857829   \n",
      "1 0 days 00:05:07.900671027   \n",
      "2 0 days 00:07:52.720673619   \n",
      "3 0 days 00:07:14.813174235   \n",
      "4 1 days 12:27:10.081644556   \n",
      "\n",
      "                                               x_gyr  \\\n",
      "0  [0.45959473, 0.4724121, 0.4446411, 0.42755127,...   \n",
      "1  [-0.13899231, -0.1379242, -0.13685608, -0.1400...   \n",
      "2  [-0.00289917, 0.04196167, 0.025939941, 0.04943...   \n",
      "3  [-0.59783936, -0.57647705, -0.557251, -0.54443...   \n",
      "4  [0.013748169, 0.0148162839999999, 0.0158844, 0...   \n",
      "\n",
      "                                               y_gyr  \\\n",
      "0  [-0.17752075, -0.12945557, -0.22131348, -0.265...   \n",
      "1  [-0.25483704, -0.25804138, -0.2601776, -0.2601...   \n",
      "2  [-0.36123657, -0.4755249, -0.42425537, -0.5118...   \n",
      "3  [0.43984985, 0.52423096, 0.6043396, 0.67697144...   \n",
      "4  [-0.00062561035, -0.0016937256, -0.0016937256,...   \n",
      "\n",
      "                                               z_gyr  \n",
      "0  [0.10437012, 0.0979614259999999, 0.103302, 0.1...  \n",
      "1  [0.07595825, 0.08343506, 0.09197998, 0.0994567...  \n",
      "2  [-0.5407715, -0.4862975999999999, -0.5151367, ...  \n",
      "3  [1.1532593, 1.1308288999999998, 1.1116028, 1.0...  \n",
      "4  [-0.023376465, -0.02230835, -0.021240234, -0.0...  \n"
     ]
    }
   ],
   "source": [
    "print(merged_df.shape)\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e995193f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (307, 11)\n",
      "  User    Device     gt   Duration_acc   Duration_gyr\n",
      "4    a  nexus4_1  stand  131230.086741  131230.081645\n",
      "Shape senza elemento confuso:  (306, 11)\n"
     ]
    }
   ],
   "source": [
    "merged_df['Duration_acc'] = merged_df['Duration_acc'].dt.total_seconds()\n",
    "merged_df['Duration_gyr'] = merged_df['Duration_gyr'].dt.total_seconds()\n",
    "\n",
    "print(\"Shape: \", merged_df.shape) \n",
    "\n",
    "# Filtro: mantiene righe con durata > 1 ora, probabilmente sono registrazioni in cui mancano timestamp rilevanti o diverse registrazioni fatte dallo stesso user in giorni diversi\n",
    "long_sessions = merged_df[\n",
    "    (merged_df['Duration_acc'] > 3600) | (merged_df['Duration_gyr'] > 3600)\n",
    "]\n",
    "\n",
    "print(long_sessions[['User', 'Device', 'gt', 'Duration_acc', 'Duration_gyr']])\n",
    "\n",
    "# Tiene solo le righe con durata <= 1 ora sia per acc sia per gyr\n",
    "merged_df = merged_df[\n",
    "    (merged_df['Duration_acc'] <= 3600) & (merged_df['Duration_gyr'] <= 3600)\n",
    "]\n",
    "\n",
    "print(\"Shape senza elemento confuso: \", merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "393ec2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    User    Device          gt    Freq_acc    Freq_gyr\n",
      "0      a  nexus4_1        bike  122.361477  122.361477\n",
      "1      a  nexus4_1         sit  194.719760  194.712145\n",
      "2      a  nexus4_1  stairsdown   95.172470   95.191521\n",
      "3      a  nexus4_1    stairsup   99.293220   99.279421\n",
      "5      a  nexus4_1        walk  186.133483  186.144424\n",
      "..   ...       ...         ...         ...         ...\n",
      "302    i  s3mini_2         sit   60.401909   60.175103\n",
      "303    i  s3mini_2  stairsdown   70.318361   70.456379\n",
      "304    i  s3mini_2    stairsup   64.321748   63.859096\n",
      "305    i  s3mini_2       stand   60.764675   60.578505\n",
      "306    i  s3mini_2        walk   76.399430   76.297190\n",
      "\n",
      "[306 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df['Freq_acc'] = merged_df.apply(                                    # calcolo la colonna delle frequenze (calcolate dinamicamente)\n",
    "    lambda row: len(row['x_acc']) / row['Duration_acc']\n",
    "    if row['Duration_acc'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "merged_df['Freq_gyr'] = merged_df.apply(\n",
    "    lambda row: len(row['x_gyr']) / row['Duration_gyr']\n",
    "    if row['Duration_gyr'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "freq_table = merged_df[['User', 'Device', 'gt', 'Freq_acc', 'Freq_gyr']]\n",
    "print(freq_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a70e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46787, 7)\n"
     ]
    }
   ],
   "source": [
    "for idx, row in merged_df.iterrows():\n",
    "    # calcolo finestre\n",
    "    x_acc_windows = window_list(row['x_acc'], row['Freq_acc'], 2)\n",
    "    y_acc_windows = window_list(row['y_acc'], row['Freq_acc'], 2)\n",
    "    z_acc_windows = window_list(row['z_acc'], row['Freq_acc'], 2)\n",
    "\n",
    "    x_gyr_windows = window_list(row['x_gyr'], row['Freq_gyr'], 2)\n",
    "    y_gyr_windows = window_list(row['y_gyr'], row['Freq_gyr'], 2)\n",
    "    z_gyr_windows = window_list(row['z_gyr'], row['Freq_gyr'], 2)\n",
    "\n",
    "    # numero minimo di finestre tra tutti i canali per evitare mismatch\n",
    "    n_windows = min(\n",
    "        len(x_acc_windows), len(y_acc_windows), len(z_acc_windows),\n",
    "        len(x_gyr_windows), len(y_gyr_windows), len(z_gyr_windows)\n",
    "    )\n",
    "\n",
    "    # genera nuove righe per ogni finestra\n",
    "    for i in range(n_windows):\n",
    "        rows.append({\n",
    "            'gt': row['gt'],\n",
    "            'x_acc': x_acc_windows[i],\n",
    "            'y_acc': y_acc_windows[i],\n",
    "            'z_acc': z_acc_windows[i],\n",
    "            'x_gyr': x_gyr_windows[i],\n",
    "            'y_gyr': y_gyr_windows[i],\n",
    "            'z_gyr': z_gyr_windows[i],\n",
    "        })\n",
    "\n",
    "windowed_df = pd.DataFrame(rows)\n",
    "\n",
    "print(windowed_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "388fcbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x_acc', 'y_acc', 'z_acc', 'x_gyr', 'y_gyr', 'z_gyr', 'activity'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "windowed_df = windowed_df.rename(columns={'gt': 'activity'})\n",
    "# Sposta la colonna 'activity' alla fine\n",
    "cols = [col for col in windowed_df.columns if col != 'activity'] + ['activity']\n",
    "windowed_df = windowed_df[cols]\n",
    "\n",
    "print(windowed_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d749b2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape delle feature (X): (46787, 6)\n",
      "Shape delle etichette (y): (46787,)\n"
     ]
    }
   ],
   "source": [
    "X = windowed_df.copy()\n",
    "y = windowed_df['activity']\n",
    "X = X.drop('activity', axis=1)\n",
    "\n",
    "print(\"Shape delle feature (X):\", X.shape)\n",
    "print(\"Shape delle etichette (y):\", y.shape)\n",
    "\n",
    "time_series = windowed_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0ef67ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estrazione Catch22: 100%|██████████| 46787/46787 [04:15<00:00, 183.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo di esecuzione per l'estrazione delle feature catch22: 256.55 secondi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_catch22, activities = catch22_time_series_features_extractor(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce391f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_catch22: (46787, 6, 22)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape X_catch22: {X_catch22.shape}\")\n",
    "np.save('hhar_catch22.npy', X_catch22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0f9f2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estrazione TSFEL: 100%|██████████| 46787/46787 [14:04<00:00, 55.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo di esecuzione per l'estrazione delle feature tsfel 3D: 844.36 secondi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_stat = tsfel.get_features_by_domain('statistical')\n",
    "cfg_temp = tsfel.get_features_by_domain('temporal')\n",
    "\n",
    "X_tsfel, activities = tsfel_time_series_features_extractor_dual(cfg_stat, cfg_temp, time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738b804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame delle feature: (46787, 6, 45)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape del DataFrame delle feature: {X_tsfel.shape}\")\n",
    "np.save('hhar_tsfel.npy', X_tsfel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
